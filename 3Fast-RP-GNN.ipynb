{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fast-RP-GNN, Relational Pooling, Mini-batching, Subgraph batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.nn import init\n",
    "from random import shuffle, randint\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.datasets import Reddit, PPI, Planetoid\n",
    "from itertools import combinations, combinations_with_replacement\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from torch_geometric.data import NeighborSampler\n",
    "from torch_geometric.utils.repeat import repeat\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "from torch_geometric.data import Data\n",
    "import logging\n",
    "import time\n",
    "from torch_cluster import neighbor_sampler\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import degree, segregate_self_loops\n",
    "from torch_geometric.utils.repeat import repeat\n",
    "from torch_geometric.nn import GCNConv, GATConv, SAGEConv, GINConv\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "\n",
    "\n",
    "\n",
    "class NeighborSamplerNew(object):\n",
    "    \n",
    "    def __init__(self, data, size=0, num_hops=2, batch_size=1, shuffle=False,\n",
    "                 drop_last=False, bipartite=False, add_self_loops=False,\n",
    "                 flow='source_to_target'):\n",
    "\n",
    "        self.data = data\n",
    "        self.size = repeat(k, hop)\n",
    "        self.num_hops = hop\n",
    "        self.batch_size = neighbor_minibatch_size\n",
    "        self.shuffle = False\n",
    "        self.drop_last = False\n",
    "        self.bipartite = False\n",
    "        self.add_self_loops = False\n",
    "        self.flow = 'source_to_target'\n",
    "\n",
    "        self.edge_index = data.edge_index\n",
    "        self.e_id = torch.arange(self.edge_index.size(1))\n",
    "        if bipartite and add_self_loops:\n",
    "            tmp = segregate_self_loops(self.edge_index, self.e_id)\n",
    "            self.edge_index, self.e_id, self.edge_index_loop = tmp[:3]\n",
    "            self.e_id_loop = self.e_id.new_full((data.num_nodes, ), -1)\n",
    "            self.e_id_loop[tmp[2][0]] = tmp[3]\n",
    "\n",
    "        assert flow in ['source_to_target', 'target_to_source']\n",
    "        self.i, self.j = (0, 1) if flow == 'target_to_source' else (1, 0)\n",
    "\n",
    "        edge_index_i, self.e_assoc = self.edge_index[self.i].sort()\n",
    "        self.edge_index_j = self.edge_index[self.j, self.e_assoc]\n",
    "        deg = degree(edge_index_i, data.num_nodes, dtype=torch.long)\n",
    "        self.cumdeg = torch.cat([deg.new_zeros(1), deg.cumsum(0)])\n",
    "\n",
    "        self.tmp = torch.empty(data.num_nodes, dtype=torch.long)\n",
    "        \n",
    "\n",
    "\n",
    "    def __get_batches__(self, subset=None):\n",
    "        r\"\"\"Returns a list of mini-batches from the initial nodes in\n",
    "        :obj:`subset`.\"\"\"\n",
    "\n",
    "        if subset is None and not self.shuffle:\n",
    "            subset = torch.arange(self.data.num_nodes, dtype=torch.long)\n",
    "        elif subset is None and self.shuffle:\n",
    "            subset = torch.randperm(self.data.num_nodes)\n",
    "        else:\n",
    "            if subset.dtype == torch.bool or subset.dtype == torch.uint8:\n",
    "                subset = subset.nonzero().view(-1)\n",
    "            if self.shuffle:\n",
    "                subset = subset[torch.randperm(subset.size(0))]\n",
    "\n",
    "        subsets = torch.split(subset, self.batch_size)\n",
    "        if self.drop_last and subsets[-1].size(0) < self.batch_size:\n",
    "            subsets = subsets[:-1]\n",
    "        assert len(subsets) > 0\n",
    "        return subsets\n",
    "\n",
    "  \n",
    "    def __produce_subgraph__(self, b_id):\n",
    "        r\"\"\"Produces a :obj:`Data` object holding the subgraph data for a given\n",
    "        mini-batch :obj:`b_id`.\"\"\"\n",
    "\n",
    "        n_ids = [b_id]\n",
    "        e_ids = []\n",
    "        edge_indices = []\n",
    "\n",
    "        for l in range(self.num_hops):\n",
    "            e_id = neighbor_sampler(n_ids[-1], self.cumdeg, self.size[l])\n",
    "            n_id = self.edge_index_j.index_select(0, e_id)\n",
    "            n_id = n_id.unique(sorted=False)\n",
    "            n_ids.append(n_id)\n",
    "            e_ids.append(self.e_assoc.index_select(0, e_id))\n",
    "            edge_index = self.data.edge_index.index_select(1, e_ids[-1])\n",
    "            edge_indices.append(edge_index)\n",
    "\n",
    "        n_id = torch.unique(torch.cat(n_ids, dim=0), sorted=False)\n",
    "        self.tmp[n_id] = torch.arange(n_id.size(0))\n",
    "        e_id = torch.cat(e_ids, dim=0)\n",
    "        edge_index = self.tmp[torch.cat(edge_indices, dim=1)]\n",
    "\n",
    "        num_nodes = n_id.size(0)\n",
    "        idx = edge_index[0] * num_nodes + edge_index[1]\n",
    "        idx, inv = idx.unique(sorted=False, return_inverse=True)\n",
    "        edge_index = torch.stack([idx / num_nodes, idx % num_nodes], dim=0)\n",
    "        e_id = e_id.new_zeros(edge_index.size(1)).scatter_(0, inv, e_id)\n",
    "\n",
    "        return Data(edge_index=edge_index, e_id=e_id, n_id=n_id, b_id=b_id,\n",
    "                    sub_b_id=self.tmp[b_id], num_nodes=num_nodes)\n",
    "\n",
    "    def __call__(self, subset=None):\n",
    "        r\"\"\"Returns a generator of :obj:`DataFlow` that iterates over the nodes\n",
    "        in :obj:`subset` in a mini-batch fashion.\n",
    "        Args:\n",
    "            subset (LongTensor or BoolTensor, optional): The initial nodes to\n",
    "                propagete messages to. If set to :obj:`None`, will iterate over\n",
    "                all nodes in the graph. (default: :obj:`None`)\n",
    "        \"\"\"\n",
    "        if self.bipartite:\n",
    "            produce = self.__produce_bipartite_data_flow__\n",
    "        else:\n",
    "            produce = self.__produce_subgraph__\n",
    "\n",
    "        for n_id in self.__get_batches__(subset):\n",
    "            yield produce(n_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the dataset, the type of prediction and the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET = 'cora'\n",
    "PREDICTION = 'link'\n",
    "RUN_COUNT = 1\n",
    "NUM_SAMPLES = 1\n",
    "PATH_TO_DATASETS_DIRECTORY = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "datasets = {\n",
    "    'reddit': Reddit(root=PATH_TO_DATASETS_DIRECTORY + '/datasets/Reddit'),\n",
    "    'cora' : Planetoid(root=PATH_TO_DATASETS_DIRECTORY + '/datasets/Cora/', name='Cora'),\n",
    "    'citeseer' : Planetoid(root=PATH_TO_DATASETS_DIRECTORY + '/datasets/CiteSeer/', name='CiteSeer'),\n",
    "    'pubmed' : Planetoid(root=PATH_TO_DATASETS_DIRECTORY + '/datasets/PubMed/', name='PubMed'),\n",
    "}\n",
    "dataset = datasets[DATASET]\n",
    "data = dataset[0]\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing Dataset Characteristics\n",
      "Name:  cora\n",
      "Total Number of Nodes:  2708\n",
      "Total Number of Training Nodes:  140\n",
      "Total Number of Val Nodes:  500\n",
      "Total Number of Test Nodes:  1000\n",
      "Num Node Features:  1433\n",
      "Num Node Classes:  7\n",
      "Number of Edges:  10556\n",
      "Number of Samples for structural:  1\n",
      "Prediction Type:  link\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing Dataset Characteristics\")\n",
    "print(\"Name: \", DATASET)\n",
    "print(\"Total Number of Nodes: \", data.num_nodes)\n",
    "print(\"Total Number of Training Nodes: \", data.train_mask.sum().item())\n",
    "print(\"Total Number of Val Nodes: \", data.val_mask.sum().item())\n",
    "print(\"Total Number of Test Nodes: \", data.test_mask.sum().item())\n",
    "print(\"Num Node Features: \", data.num_features)\n",
    "print(\"Num Node Classes: \", dataset.num_classes)\n",
    "print(\"Number of Edges: \", data.edge_index.shape[1])\n",
    "print(\"Number of Samples for structural: \", NUM_SAMPLES)\n",
    "print(\"Prediction Type: \", PREDICTION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data.train_mask = 1 - data.val_mask - data.test_mask\n",
    "data.train_mask = ~(data.val_mask + data.test_mask)\n",
    "\n",
    "adj_mat = torch.zeros((data.num_nodes,data.num_nodes))\n",
    "edges = data.edge_index.t()\n",
    "adj_mat[edges[:,0], edges[:,1]] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the non-overlapping induced subgraphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_train = adj_mat[data.train_mask].t()[data.train_mask].t()\n",
    "adj_validation = adj_mat[data.val_mask].t()[data.val_mask].t()\n",
    "adj_test = adj_mat[data.test_mask].t()[data.test_mask].t()\n",
    "\n",
    "\n",
    "GnnLayer=GATConv\n",
    "gnn_model = 0\n",
    "epochs = 100\n",
    "validation_acc = 0\n",
    "small_samples = 200\n",
    "\n",
    "minibatch_size=16\n",
    "neighbor_minibatch_size=2 #for current implementation use 2 for now\n",
    "k=5\n",
    "hop=2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corrupt a small fraction of the edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corrupt_adj(adj_mat, task, percent=2):\n",
    "    \"\"\" Returns the corrupted version of the adjacency matrix \"\"\"\n",
    "    if task == 'link':\n",
    "        edges = adj_mat.triu().nonzero()\n",
    "        num_edges = edges.shape[0]\n",
    "        num_to_corrupt = int(percent/100.0 * num_edges)\n",
    "        random_corruption = np.random.randint(num_edges, size=num_to_corrupt)\n",
    "        adj_mat_corrupted = adj_mat.clone()\n",
    "        false_edges, false_non_edges = [], []\n",
    "        #Edge Corruption\n",
    "        for ed in edges[random_corruption]:\n",
    "            adj_mat_corrupted[ed[0], ed[1]] = 0\n",
    "            adj_mat_corrupted[ed[1], ed[0]] = 0\n",
    "            false_non_edges.append(ed.tolist())\n",
    "        #Non Edge Corruption\n",
    "        random_non_edge_corruption = list(np.random.randint(adj_mat.shape[0], size = 6*num_to_corrupt))\n",
    "        non_edge_to_corrupt = []\n",
    "        for k in range(len(random_non_edge_corruption)-1):\n",
    "            to_check = [random_non_edge_corruption[k], random_non_edge_corruption[k+1]]\n",
    "            if to_check not in edges.tolist():\n",
    "                non_edge_to_corrupt.append(to_check)\n",
    "            if len(non_edge_to_corrupt) == num_to_corrupt:\n",
    "                break\n",
    "        non_edge_to_corrupt = torch.Tensor(non_edge_to_corrupt).type(torch.int16)\n",
    "        for n_ed in non_edge_to_corrupt:\n",
    "            adj_mat_corrupted[n_ed[0], n_ed[1]] = 1\n",
    "            adj_mat_corrupted[n_ed[1], n_ed[0]] = 1\n",
    "            false_edges.append(n_ed.tolist())\n",
    "    return adj_mat_corrupted, false_edges, false_non_edges\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train edge index: tensor([[   1,    1,    1,  ..., 1205, 1205, 1207],\n",
      "        [   2,  152,  154,  ...,  789, 1124,  941]])\n"
     ]
    }
   ],
   "source": [
    "adj_train_corrupted, train_false_edges, train_false_non_edges = corrupt_adj(adj_train, 'link', percent=2)\n",
    "adj_val_corrupted, val_false_edges, val_false_non_edges = corrupt_adj(adj_validation, 'link', percent=2)\n",
    "adj_test_corrupted, test_false_edges, test_false_non_edges  = corrupt_adj(adj_test, 'link', percent=2)\n",
    "\n",
    "G_train=Data(edge_index=(adj_train_corrupted.nonzero()).t(), x=data.x[data.train_mask])\n",
    "print(\"train edge index:\", G_train.edge_index)\n",
    "G_val=Data(edge_index=(adj_val_corrupted.nonzero()).t(), x=data.x[data.val_mask])\n",
    "G_test=Data(edge_index=(adj_test_corrupted.nonzero()).t(), x=data.x[data.test_mask])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the GNN network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nneurons = 256\n",
    "Input_Dim_rep = data.num_features + 1 #aditional feature for expressiveness of the Graph Convolution\n",
    "\n",
    "class GnnNew(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GnnNew, self).__init__()        \n",
    "     \n",
    "        if(GnnLayer==GINConv):\n",
    "            self.MLP1 = nn.Linear(Input_Dim_rep,Nneurons)\n",
    "            self.MLP2 = nn.Linear(Nneurons,Nneurons)\n",
    "            self.GNN_layer1 = GnnLayer(self.MLP1)\n",
    "            self.GNN_layer2 = GnnLayer(self.MLP2)  \n",
    "        \n",
    "        else:\n",
    "            self.GNN_layer1 = GnnLayer(Input_Dim_rep,Nneurons)\n",
    "            self.GNN_layer2 = GnnLayer(Nneurons,Nneurons)             \n",
    "    \n",
    "        self.ds_layer_1 = nn.Linear(Nneurons, Nneurons)\n",
    "        self.ro_1 = nn.Linear(Nneurons, Nneurons)      \n",
    "              \n",
    "        self.linear_1 = nn.Linear(Nneurons,Nneurons)\n",
    "        self.linear_2 = nn.Linear(Nneurons,2)\n",
    "        \n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        \n",
    "    def forward(self, subgraphs, nodes, edges):        \n",
    "        \n",
    "        \n",
    "        countNode = torch.zeros((len(nodes)),requires_grad=False).to(device)\n",
    "        tensorNode = torch.zeros((len(nodes), Nneurons)).to(device)\n",
    "        \n",
    "        for i in range(len(subgraphs)):\n",
    "        \n",
    "            graph=subgraphs[i]\n",
    "            #print(graph.num_nodes,graph.num_edges)....23\n",
    "            feat=graph.x_feature  #(23,1434)\n",
    "           # print(\"feat \",feat)\n",
    "            lenFeat=len(graph.x_feature)  #2\n",
    "            #print(\"lenFeat\",lenFeat)#........4]2\n",
    "            ed_i=graph.edge_index  #(2,42)\n",
    "            Nfeat=feat[0].shape[0]\n",
    "            \n",
    "            Ysum = torch.zeros((Nfeat, Nneurons)).to(device)\n",
    "            \n",
    "            for j in range(lenFeat):      #2 version of unique id consideration     \n",
    "                #print(\"j\",j)\n",
    "                #print(\"featJ\",feat[j], feat[j].shape)\n",
    "                #print(\"edge\",ed_i, ed_i.shape)\n",
    "                y=self.GNN_layer1(feat[j],ed_i)\n",
    "                y=self.relu(y)\n",
    "\n",
    "                y=self.GNN_layer2(y,ed_i)\n",
    "                y=self.relu(y)       \n",
    "                Ysum=Ysum+y\n",
    "               # print(Ysum)\n",
    "            Yavg=Ysum/lenFeat   #average for unique ID\n",
    "            \n",
    "            for node_i_d in graph.b_id:        #for these nodes who created the subgraph around     \n",
    "                # b_id holds a one-dimensional tensor of node indices to produce subgraphs \n",
    "                #for and e_id and n_id hold the indices that got samples from the original graph for edges \n",
    "                #and nodes respectively. Since you are having a batch size of 1, b_id should be of size 1.\n",
    "#                 print(\"graph.nid\", graph.n_id)\n",
    "#                 print(\"nodeId\", node_i_d)\n",
    "#                 print(\"graph.nid=nodeId\", (graph.n_id==node_i_d))\n",
    "#                 print(\"subindex\", (graph.n_id==node_i_d).nonzero()[0])\n",
    "                sub_index=0\n",
    "                for i_d in range(len(graph.n_id)):  #check all the nodes in the subgraph\n",
    "                    if graph.n_id[i_d]==node_i_d:\n",
    "                        sub_index=i_d              #find index of the b_id node in the subgraph...\n",
    "                        break;\n",
    "                #print(\"subindexnew\", sub_index)\n",
    "                #sub_index=(graph.n_id==node_i_d).nonzero()[0]\n",
    "                sub_x=Yavg[sub_index,:]   #get Yavg row for that index...\n",
    "                node_index=0\n",
    "                for i_d in range(len(nodes)):\n",
    "                    if nodes[i_d]==node_i_d:  #get these node in the all nodes in the main graph\n",
    "                        node_index=i_d\n",
    "                        break;\n",
    "                \n",
    "                #node_index=(nodes==node_i_d).nonzero()[0]\n",
    "#                 print(\"node.nid\", nodes)\n",
    "#                 print(\"nodeId\", node_i_d)\n",
    "#                 print(\"nodes=nodeId\", (nodes==node_i_d))\n",
    "#                 print(\"nodeindex\", (nodes==node_i_d).nonzero()[0], \"actual Nid: \",node_index)                \n",
    "#                 print(sub_x.shape)\n",
    "#                 print(sub_x.view(-1).shape)\n",
    "                tensorNode[node_index,:]+=sub_x.view(-1)  #update Yavg in the original graph node position\n",
    "                countNode[node_index]+=1     #increase the node count original graph \n",
    "#         print(tensorNode)\n",
    "#         print(countNode)\n",
    "#         print(countNode[:, None])\n",
    "        #print(countNode.unsqueeze(0))\n",
    "        #print(countNode.unsqueeze(1))\n",
    "       \n",
    "        #tensorNode=tensorNode / countNode[:, None] \n",
    "        linkN=0\n",
    "        returnTensor = torch.zeros((len(edges), Nneurons)).to(device)\n",
    "        #print(\"retTensor\", returnTensor)\n",
    "        \n",
    "        tensorNode=tensorNode / countNode.unsqueeze(1)\n",
    "        for e in edges:\n",
    "            for i_d in range(len(nodes)):\n",
    "                    if nodes[i_d]==e[0]:\n",
    "                        point1=i_d\n",
    "                        break;\n",
    "            for i_d in range(len(nodes)):\n",
    "                    if nodes[i_d]==e[1]:\n",
    "                        point2=i_d\n",
    "                        break;\n",
    "#             u=(nodes==e[0]).nonzero()[0]\n",
    "#             v=(nodes==e[1]).nonzero()[0]\n",
    "  #          print(\"uv\",u,v,point1,point2)\n",
    "            u=tensorNode[point1,:]                        \n",
    "            v=tensorNode[point2,:]\n",
    "                        \n",
    "            ##we can use pooling                                    \n",
    "            u_v=u+v            \n",
    "            returnTensor[linkN,:]=u_v\n",
    "            linkN+=1\n",
    "        \n",
    "        \n",
    "        #One Hidden Layer for predictor        \n",
    "        returnTensor = self.linear_1(returnTensor)\n",
    "        returnTensor = self.relu(returnTensor)\n",
    "        returnTensor = self.linear_2(returnTensor)\n",
    "        \n",
    "        return returnTensor\n",
    "\n",
    "    def compute_loss(self, sub_graphs, nodes, edges, target):\n",
    "        \n",
    "        pred = self.forward(sub_graphs, nodes, edges)        \n",
    "        loss = F.cross_entropy(pred, target)                \n",
    "        \n",
    "        return loss\n",
    "    \n",
    "    def predict(self, sub_graphs, nodes, edges, target):\n",
    "        \n",
    "        pred = self.forward(sub_graphs, nodes, edges)        \n",
    "        loss = F.cross_entropy(pred, target)\n",
    "        \n",
    "        return loss, pred\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample positive and negative edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_equal_number_edges_non_edges(adj_mat, false_non_edges, false_edges, small_samples):\n",
    "    edges = adj_mat.nonzero()\n",
    "    num_edges = edges.shape[0]\n",
    "    inverse_adj_mat = 1 - adj_mat\n",
    "    non_edges = inverse_adj_mat.nonzero()\n",
    "    num_non_edges  = non_edges.shape[0]\n",
    "    \n",
    "    edges_sampled = edges[np.random.randint(num_edges, size=small_samples)]\n",
    "    non_edges_sampled = non_edges[np.random.randint(num_non_edges, size=small_samples)]\n",
    "    final_edges = []\n",
    "    final_non_edges = []\n",
    "    for ed in edges_sampled.tolist():\n",
    "        if ed not in false_edges:\n",
    "            final_edges.append(ed)\n",
    "    final_edges += false_non_edges\n",
    "    for n_ed in non_edges_sampled.tolist():\n",
    "        if n_ed not in false_non_edges:\n",
    "            final_non_edges.append(n_ed)\n",
    "    final_non_edges += false_edges\n",
    "\n",
    "    return final_edges, final_non_edges\n",
    "\n",
    "\n",
    "\n",
    "def sample_train_edges_nearest_neighbor(train_feature, adj_mat, false_non_edges, false_edges, small_samples):\n",
    "    edges = adj_mat.nonzero()\n",
    "    num_edges = edges.shape[0]\n",
    "    \n",
    "    k=5\n",
    "    A = kneighbors_graph(train_feature, k, mode=\"connectivity\", metric=\"cosine\", include_self=False)        \n",
    "    (u,v)=A.nonzero()\n",
    "    u=torch.Tensor(u).type(torch.long)\n",
    "    v=torch.Tensor(v).type(torch.long)\n",
    "    possible_edges=torch.stack((u,v),dim=1)\n",
    "    possible_adj_mat = torch.zeros((adj_mat.shape))\n",
    "    possible_adj_mat[possible_edges[:,0], possible_edges[:,1]] = 1\n",
    "    \n",
    "    inverse_adj_mat=possible_adj_mat-adj_mat\n",
    "    inverse_adj_mat[inverse_adj_mat==-1]=0\n",
    "    non_edges = inverse_adj_mat.nonzero()  \n",
    "    \n",
    "   # print(non_edges.shape)\n",
    "    \n",
    "    num_non_edges  = non_edges.shape[0]\n",
    "    edges_sampled = edges[np.random.randint(num_edges, size=small_samples)]\n",
    "    non_edges_sampled = non_edges[np.random.randint(num_non_edges, size=small_samples)]\n",
    "    final_edges = []\n",
    "    final_non_edges = []\n",
    "    for ed in edges_sampled.tolist():\n",
    "        if ed not in false_edges:\n",
    "            final_edges.append(ed)\n",
    "    final_edges += false_non_edges\n",
    "    for n_ed in non_edges_sampled.tolist():\n",
    "        if n_ed not in false_non_edges:\n",
    "            final_non_edges.append(n_ed)\n",
    "    final_non_edges += false_edges\n",
    "\n",
    "    return final_edges, final_non_edges\n",
    "\n",
    "# edges, non_edges = sample_equal_number_edges_non_edges(adj_train_corrupted, false_non_edges=train_false_non_edges, false_edges=train_false_edges, small_samples=small_samples)\n",
    "# edges, non_edges = sample_train_edges_nearest_neighbor(G_train.x, adj_train_corrupted, false_non_edges=train_false_non_edges, false_edges=train_false_edges, small_samples=small_samples)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Minibatch of edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiniBatcher(object):\n",
    "    def __init__(self, batch_size, n_examples, shuffle=True):\n",
    "        assert batch_size <= n_examples, \"Error: batch_size is larger than n_examples\"\n",
    "        self.batch_size = batch_size\n",
    "        self.n_examples = n_examples\n",
    "        self.shuffle = shuffle\n",
    "        logging.info(\"batch_size={}, n_examples={}\".format(batch_size, n_examples))\n",
    "\n",
    "        self.idxs = np.arange(self.n_examples)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.idxs)\n",
    "        self.current_start = 0\n",
    "\n",
    "    def get_one_batch(self):\n",
    "        self.idxs = np.arange(self.n_examples)\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.idxs)\n",
    "        self.current_start = 0\n",
    "        while self.current_start < self.n_examples:\n",
    "            batch_idxs = self.idxs[self.current_start:self.current_start+self.batch_size]\n",
    "            self.current_start += self.batch_size\n",
    "            yield torch.LongTensor(batch_idxs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model(select):\n",
    "    \n",
    "    if select==\"val\":\n",
    "        G_data=G_val\n",
    "        #neighbor_sampler=val_neighbor_sampler        \n",
    "        adj_corrupted=adj_val_corrupted\n",
    "        false_non_edges=val_false_non_edges\n",
    "        false_edges=val_false_edges\n",
    "    if select==\"test\":\n",
    "        G_data=G_test\n",
    "        #neighbor_sampler=test_neighbor_sampler        \n",
    "        adj_corrupted=adj_test_corrupted\n",
    "        false_non_edges=test_false_non_edges\n",
    "        false_edges=test_false_edges\n",
    "                \n",
    "    neighbor_sampler=NeighborSamplerNew(G_data)\n",
    "    gnn_model.eval()\n",
    "    preds=np.array([])\n",
    "    targets=np.array([])\n",
    "    total_loss=0\n",
    "    \n",
    "    edges, non_edges = sample_equal_number_edges_non_edges(adj_corrupted, false_non_edges, false_edges, small_samples)    \n",
    "    samples = torch.cat((torch.Tensor(edges), torch.Tensor(non_edges)),dim=0).type(torch.long).to(device)\n",
    "    true_target = torch.cat((torch.ones(len(edges)), torch.zeros(len(non_edges))),dim=0).type(torch.long).to(device)\n",
    "    \n",
    "    batcher = MiniBatcher(minibatch_size, len(samples)) if minibatch_size > 0 else MiniBatcher(len(samples), len(samples))\n",
    "    \n",
    "    t_start = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for x_idxs in batcher.get_one_batch():\n",
    "            x_idxs = x_idxs.to(device)\n",
    "\n",
    "            x_edges=samples[x_idxs]\n",
    "            y_target=true_target[x_idxs]\n",
    "            \n",
    "            nodex=torch.flatten(x_edges)            \n",
    "            \n",
    "            nodes=torch.unique(nodex.view(-1))\n",
    "\n",
    "            #subgraphs=NewSubgraphMaker(G_data, x_edges, nodex)\n",
    "                \n",
    "            graphGenerator=neighbor_sampler(nodex.cpu())    \n",
    "            subgraphs=[]\n",
    "            for graph in graphGenerator:        \n",
    "                sub_feature=torch.Tensor(G_data.x[graph.n_id])      \n",
    "                x_feature=[]        \n",
    "                for i in range(2):\n",
    "                    unique_feature=torch.zeros(len(sub_feature),1)\n",
    "                    for i_d in range(len(graph.n_id)):\n",
    "                            if graph.b_id[i]==graph.n_id[i_d]: #b_id hold the id of the nodes for which subgraph created\n",
    "                                pointu=i_d\n",
    "                                break;           \n",
    "                    unique_feature[pointu]=1                        \n",
    "                    x_feature.append(torch.cat((sub_feature,unique_feature),dim=1).to(device))\n",
    "                graph.x_feature=x_feature\n",
    "                subgraphs.append(graph.to(device))        \n",
    "            \n",
    "            loss, pred=gnn_model.predict(subgraphs, nodes, x_edges, y_target)                          \n",
    "            total_loss+=loss.item()\n",
    "            \n",
    "            pred = F.log_softmax(pred, dim=1)\n",
    "            pred = pred.detach().to(\"cpu\").numpy()\n",
    "            pred = np.argmax(pred, axis=1)\n",
    "                          \n",
    "            preds = np.append(preds,pred)\n",
    "            targets = np.append(targets,y_target.detach().to(\"cpu\").numpy())\n",
    "        \n",
    "\n",
    "    micro=f1_score(targets, preds, average='micro')\n",
    "    weighted=f1_score(targets, preds, average='weighted')\n",
    "    acc=accuracy_score(targets, preds)\n",
    "    \n",
    "    return total_loss, acc, micro, weighted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Accuracy and Loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_plot(train_data, valid_data, name='Loss'):\n",
    "    \"\"\"Plot\n",
    "        Plot one figure: accurace/loss vs. epoch and accuracy vs. epoch\n",
    "    \"\"\"\n",
    "    n = len(train_data)\n",
    "    xs = np.arange(n)\n",
    "\n",
    "    # plot train and test accuracies\n",
    "    plt.clf()\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.plot(xs, train_data, '--', linewidth=2, label='train')\n",
    "    ax.plot(xs, valid_data, '-', linewidth=2, label='valid')\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "    ax.set_ylabel(name)\n",
    "    ax.legend(loc='lower right')\n",
    "    plt.show()\n",
    "    plt.savefig('train_valid_'+name+'.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch time:  9.318790435791016\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 0] Train Loss: 19.340339183807373, Train Accuracy: 0.5540540540540541, Val Loss 17.75026422739029, Val Accuracy: 0.5247524752475248\n",
      "Minibatch time:  9.210293054580688\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 1] Train Loss: 18.372650504112244, Train Accuracy: 0.6117381489841986, Val Loss 16.858271300792694, Val Accuracy: 0.6142506142506142\n",
      "Minibatch time:  9.400168895721436\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 2] Train Loss: 17.503827691078186, Train Accuracy: 0.6659192825112108, Val Loss 15.931458532810211, Val Accuracy: 0.6904176904176904\n",
      "Minibatch time:  9.340213060379028\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 3] Train Loss: 16.40869152545929, Train Accuracy: 0.7438202247191011, Val Loss 17.097224533557892, Val Accuracy: 0.597051597051597\n",
      "Minibatch time:  8.976438760757446\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 4] Train Loss: 16.148842453956604, Train Accuracy: 0.7280898876404495, Val Loss 15.642112106084824, Val Accuracy: 0.7058823529411765\n",
      "Minibatch time:  9.320336103439331\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 5] Train Loss: 15.528204530477524, Train Accuracy: 0.7370786516853932, Val Loss 20.425907641649246, Val Accuracy: 0.5221674876847291\n",
      "Minibatch time:  10.646404027938843\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 6] Train Loss: 15.647184252738953, Train Accuracy: 0.7331838565022422, Val Loss 18.39313107728958, Val Accuracy: 0.5285359801488834\n",
      "Minibatch time:  9.015415668487549\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 7] Train Loss: 14.725830137729645, Train Accuracy: 0.759009009009009, Val Loss 15.914663642644882, Val Accuracy: 0.645320197044335\n",
      "Minibatch time:  8.810542106628418\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 8] Train Loss: 15.44084495306015, Train Accuracy: 0.7352941176470589, Val Loss 16.919804751873016, Val Accuracy: 0.6314496314496314\n",
      "Minibatch time:  8.844520330429077\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 9] Train Loss: 15.546139121055603, Train Accuracy: 0.7235955056179775, Val Loss 15.46961310505867, Val Accuracy: 0.6724137931034483\n",
      "Minibatch time:  9.713982105255127\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 10] Train Loss: 13.996669173240662, Train Accuracy: 0.7755102040816326, Val Loss 14.751618087291718, Val Accuracy: 0.6641975308641975\n",
      "Minibatch time:  8.954453945159912\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 11] Train Loss: 12.700663432478905, Train Accuracy: 0.7972972972972973, Val Loss 17.54616452753544, Val Accuracy: 0.6108374384236454\n",
      "Minibatch time:  8.889493227005005\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 12] Train Loss: 12.067476972937584, Train Accuracy: 0.8049886621315193, Val Loss 14.083896696567535, Val Accuracy: 0.771712158808933\n",
      "Minibatch time:  9.174315929412842\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 13] Train Loss: 9.807791262865067, Train Accuracy: 0.8843537414965986, Val Loss 9.27342601120472, Val Accuracy: 0.8740740740740741\n",
      "Minibatch time:  9.316230535507202\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 14] Train Loss: 8.390714809298515, Train Accuracy: 0.8893905191873589, Val Loss 7.568635895848274, Val Accuracy: 0.9054726368159204\n",
      "Minibatch time:  10.894250392913818\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 15] Train Loss: 7.916378173977137, Train Accuracy: 0.8834080717488789, Val Loss 6.938161842525005, Val Accuracy: 0.9014778325123153\n",
      "Minibatch time:  9.171318769454956\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 16] Train Loss: 6.366601850837469, Train Accuracy: 0.9051918735891648, Val Loss 5.914586566388607, Val Accuracy: 0.9044117647058824\n",
      "Minibatch time:  9.056390047073364\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 17] Train Loss: 3.731726946309209, Train Accuracy: 0.9596412556053812, Val Loss 8.255833399482071, Val Accuracy: 0.8960396039603961\n",
      "Minibatch time:  9.28724479675293\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 18] Train Loss: 5.114684775471687, Train Accuracy: 0.9211711711711712, Val Loss 4.815830217674375, Val Accuracy: 0.9310344827586207\n",
      "Minibatch time:  9.524096965789795\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 19] Train Loss: 3.283325245603919, Train Accuracy: 0.9617117117117117, Val Loss 4.255301641300321, Val Accuracy: 0.9432098765432099\n",
      "Minibatch time:  9.229281187057495\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 20] Train Loss: 3.027951022144407, Train Accuracy: 0.9662921348314607, Val Loss 5.267294318880886, Val Accuracy: 0.9261083743842364\n",
      "Minibatch time:  8.857513904571533\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 21] Train Loss: 2.658200932200998, Train Accuracy: 0.9618834080717489, Val Loss 7.413016630336642, Val Accuracy: 0.9158415841584159\n",
      "Minibatch time:  8.852514505386353\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 22] Train Loss: 2.9361820984631777, Train Accuracy: 0.9615384615384616, Val Loss 5.853770287707448, Val Accuracy: 0.9211822660098522\n",
      "Minibatch time:  8.829530954360962\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 23] Train Loss: 3.234118429943919, Train Accuracy: 0.952808988764045, Val Loss 4.341402646852657, Val Accuracy: 0.9432098765432099\n",
      "Minibatch time:  9.555082082748413\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 24] Train Loss: 2.6701193368062377, Train Accuracy: 0.9708520179372198, Val Loss 4.126370803453028, Val Accuracy: 0.9459459459459459\n",
      "Minibatch time:  9.928847789764404\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 25] Train Loss: 2.697974788490683, Train Accuracy: 0.9594594594594594, Val Loss 4.911630085669458, Val Accuracy: 0.946078431372549\n",
      "Minibatch time:  9.209295272827148\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 26] Train Loss: 1.5739450459368527, Train Accuracy: 0.981941309255079, Val Loss 4.968744503566995, Val Accuracy: 0.9556650246305419\n",
      "Minibatch time:  8.894489049911499\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 27] Train Loss: 2.4314576386241242, Train Accuracy: 0.9662162162162162, Val Loss 5.181078761816025, Val Accuracy: 0.958128078817734\n",
      "Minibatch time:  9.221286058425903\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 28] Train Loss: 2.677495910320431, Train Accuracy: 0.9706546275395034, Val Loss 4.62624212843366, Val Accuracy: 0.9385749385749386\n",
      "Minibatch time:  8.744581699371338\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 29] Train Loss: 3.814321242971346, Train Accuracy: 0.9570135746606335, Val Loss 3.3760503688827157, Val Accuracy: 0.9557739557739557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch time:  8.938459873199463\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 30] Train Loss: 2.429834933951497, Train Accuracy: 0.9820627802690582, Val Loss 3.964103718753904, Val Accuracy: 0.9507389162561576\n",
      "Minibatch time:  8.761571645736694\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 31] Train Loss: 2.234539681347087, Train Accuracy: 0.9706546275395034, Val Loss 3.757644392317161, Val Accuracy: 0.9534313725490197\n",
      "Minibatch time:  8.818533897399902\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 32] Train Loss: 2.264003671007231, Train Accuracy: 0.9751693002257337, Val Loss 3.7580246364232153, Val Accuracy: 0.9604938271604938\n",
      "Minibatch time:  9.164320230484009\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 33] Train Loss: 1.082668285467662, Train Accuracy: 0.9932584269662922, Val Loss 4.629137580865063, Val Accuracy: 0.9583333333333334\n",
      "Minibatch time:  10.11673092842102\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 34] Train Loss: 1.9492059094482102, Train Accuracy: 0.9796839729119639, Val Loss 6.750876179081388, Val Accuracy: 0.9385749385749386\n",
      "Minibatch time:  9.025407791137695\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 35] Train Loss: 1.5946199535392225, Train Accuracy: 0.9819819819819819, Val Loss 3.288127531995997, Val Accuracy: 0.9631449631449631\n",
      "Minibatch time:  9.33421516418457\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 36] Train Loss: 2.043214378412813, Train Accuracy: 0.9752252252252253, Val Loss 4.453059670748189, Val Accuracy: 0.9555555555555556\n",
      "Minibatch time:  8.8884916305542\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 37] Train Loss: 1.2121367247309536, Train Accuracy: 0.9887387387387387, Val Loss 5.5185409635305405, Val Accuracy: 0.9652605459057072\n",
      "Minibatch time:  9.139337062835693\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 38] Train Loss: 2.219156907289289, Train Accuracy: 0.963882618510158, Val Loss 3.6038289128337055, Val Accuracy: 0.9605911330049262\n",
      "Minibatch time:  8.794550895690918\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 39] Train Loss: 0.6093481644056737, Train Accuracy: 0.995475113122172, Val Loss 5.539909668135806, Val Accuracy: 0.9529702970297029\n",
      "Minibatch time:  8.82053518295288\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 40] Train Loss: 1.8982064384035766, Train Accuracy: 0.9820224719101124, Val Loss 5.532816498074681, Val Accuracy: 0.9411764705882353\n",
      "Minibatch time:  8.748579740524292\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 41] Train Loss: 2.892688714666292, Train Accuracy: 0.9661399548532731, Val Loss 3.857724385103211, Val Accuracy: 0.9553349875930521\n",
      "Minibatch time:  8.883498668670654\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 42] Train Loss: 2.674737789668143, Train Accuracy: 0.9683972911963883, Val Loss 3.5508980967570096, Val Accuracy: 0.9631449631449631\n",
      "Minibatch time:  8.858511209487915\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 43] Train Loss: 1.640694175614044, Train Accuracy: 0.9796839729119639, Val Loss 4.820559643325396, Val Accuracy: 0.9558823529411765\n",
      "Minibatch time:  10.813300609588623\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 44] Train Loss: 3.0857740356586874, Train Accuracy: 0.9659090909090909, Val Loss 3.7597854183986783, Val Accuracy: 0.9534313725490197\n",
      "Minibatch time:  8.776562690734863\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 45] Train Loss: 1.510589376790449, Train Accuracy: 0.9819819819819819, Val Loss 3.4727190193952993, Val Accuracy: 0.9679802955665024\n",
      "Minibatch time:  9.137336015701294\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 46] Train Loss: 2.272520155645907, Train Accuracy: 0.9819819819819819, Val Loss 4.871379688265733, Val Accuracy: 0.9482758620689655\n",
      "Minibatch time:  8.916476249694824\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 47] Train Loss: 2.510805232450366, Train Accuracy: 0.9707207207207207, Val Loss 4.272322541102767, Val Accuracy: 0.9361179361179361\n",
      "Minibatch time:  8.704608917236328\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 48] Train Loss: 1.193405507132411, Train Accuracy: 0.9865168539325843, Val Loss 3.553592429670971, Val Accuracy: 0.958128078817734\n",
      "Minibatch time:  8.799547910690308\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 49] Train Loss: 1.6633534517604858, Train Accuracy: 0.9865470852017937, Val Loss 5.357068480923772, Val Accuracy: 0.9338235294117647\n",
      "Minibatch time:  8.729591608047485\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 50] Train Loss: 1.7323318305425346, Train Accuracy: 0.9864864864864865, Val Loss 4.632024595281109, Val Accuracy: 0.9458128078817734\n",
      "Minibatch time:  8.72659420967102\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 51] Train Loss: 1.3426211602636613, Train Accuracy: 0.9887892376681614, Val Loss 5.03771303317626, Val Accuracy: 0.9580246913580247\n",
      "Minibatch time:  8.627654790878296\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 52] Train Loss: 2.009099091461394, Train Accuracy: 0.9864253393665159, Val Loss 4.324522166978568, Val Accuracy: 0.9583333333333334\n",
      "Minibatch time:  8.763570308685303\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 53] Train Loss: 2.273758824914694, Train Accuracy: 0.9775280898876404, Val Loss 4.654715167125687, Val Accuracy: 0.9433497536945813\n",
      "Minibatch time:  10.596018552780151\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 54] Train Loss: 1.5089321392588317, Train Accuracy: 0.9842696629213483, Val Loss 4.409340914804488, Val Accuracy: 0.958128078817734\n",
      "Minibatch time:  8.843520879745483\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 55] Train Loss: 1.4085806423099712, Train Accuracy: 0.9842342342342343, Val Loss 4.335593215888366, Val Accuracy: 0.9580246913580247\n",
      "Minibatch time:  8.75857400894165\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 56] Train Loss: 2.6020008560735732, Train Accuracy: 0.9751693002257337, Val Loss 3.8058976447209716, Val Accuracy: 0.9556650246305419\n",
      "Minibatch time:  8.709602117538452\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 57] Train Loss: 1.0894688999978825, Train Accuracy: 0.9886877828054299, Val Loss 5.460366845480166, Val Accuracy: 0.9433497536945813\n",
      "Minibatch time:  8.70160961151123\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 58] Train Loss: 1.0551027400651947, Train Accuracy: 0.9864559819413092, Val Loss 4.326034153811634, Val Accuracy: 0.9607843137254902\n",
      "Minibatch time:  8.710602283477783\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 59] Train Loss: 1.603973580058664, Train Accuracy: 0.9864864864864865, Val Loss 4.544096407233155, Val Accuracy: 0.9580246913580247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch time:  8.725593328475952\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 60] Train Loss: 1.3690369701944292, Train Accuracy: 0.9865470852017937, Val Loss 6.581708222802263, Val Accuracy: 0.9530864197530864\n",
      "Minibatch time:  8.689615726470947\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 61] Train Loss: 1.2337464119773358, Train Accuracy: 0.9865168539325843, Val Loss 3.52386671397835, Val Accuracy: 0.9656019656019657\n",
      "Minibatch time:  8.63065481185913\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 62] Train Loss: 0.5513289175578393, Train Accuracy: 0.9955056179775281, Val Loss 7.846517393976683, Val Accuracy: 0.9359605911330049\n",
      "Minibatch time:  9.515103101730347\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 63] Train Loss: 0.5132995554740774, Train Accuracy: 0.9910313901345291, Val Loss 4.260449196895934, Val Accuracy: 0.9652605459057072\n",
      "Minibatch time:  10.935224771499634\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 64] Train Loss: 1.9523403375642374, Train Accuracy: 0.9864559819413092, Val Loss 6.536049308080692, Val Accuracy: 0.9630541871921182\n",
      "Minibatch time:  8.908480405807495\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 65] Train Loss: 1.152489836793393, Train Accuracy: 0.9932735426008968, Val Loss 3.7607129874522798, Val Accuracy: 0.9626865671641791\n",
      "Minibatch time:  8.753578662872314\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 66] Train Loss: 1.080405254557263, Train Accuracy: 0.9886877828054299, Val Loss 7.206344889593311, Val Accuracy: 0.9404466501240695\n",
      "Minibatch time:  8.875501155853271\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 67] Train Loss: 1.6777429978828877, Train Accuracy: 0.9752808988764045, Val Loss 5.420370766660199, Val Accuracy: 0.9482758620689655\n",
      "Minibatch time:  8.815538167953491\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 68] Train Loss: 0.6571483581792563, Train Accuracy: 0.9932584269662922, Val Loss 5.225273654301418, Val Accuracy: 0.9556650246305419\n",
      "Minibatch time:  8.882497310638428\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 69] Train Loss: 2.2898093935800716, Train Accuracy: 0.9774774774774775, Val Loss 4.046248982427642, Val Accuracy: 0.9705159705159705\n",
      "Minibatch time:  9.178312540054321\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 70] Train Loss: 1.5458573317155242, Train Accuracy: 0.9797297297297297, Val Loss 4.349579567031469, Val Accuracy: 0.9629629629629629\n",
      "Minibatch time:  8.921472549438477\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 71] Train Loss: 1.1347671763505787, Train Accuracy: 0.990990990990991, Val Loss 4.457305543794064, Val Accuracy: 0.9606879606879607\n",
      "Minibatch time:  8.77256464958191\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 72] Train Loss: 2.3882642555981874, Train Accuracy: 0.9751693002257337, Val Loss 4.140001494670287, Val Accuracy: 0.9656862745098039\n",
      "Minibatch time:  8.897487163543701\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 73] Train Loss: 0.8474825221346691, Train Accuracy: 0.9932584269662922, Val Loss 6.955473505309783, Val Accuracy: 0.9362745098039216\n",
      "Minibatch time:  10.238656759262085\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 74] Train Loss: 0.8204696644679643, Train Accuracy: 0.9865168539325843, Val Loss 5.7185241733677685, Val Accuracy: 0.9484029484029484\n",
      "Minibatch time:  8.923470973968506\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 75] Train Loss: 0.8748691083164886, Train Accuracy: 0.9864864864864865, Val Loss 7.249377108120825, Val Accuracy: 0.9508599508599509\n",
      "Minibatch time:  8.785557746887207\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 76] Train Loss: 0.6823157279286534, Train Accuracy: 0.9932584269662922, Val Loss 6.3610290871874895, Val Accuracy: 0.9507389162561576\n",
      "Minibatch time:  8.867506980895996\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 77] Train Loss: 1.4314797159750015, Train Accuracy: 0.9887387387387387, Val Loss 5.12014163013373, Val Accuracy: 0.9603960396039604\n",
      "Minibatch time:  8.8075430393219\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 78] Train Loss: 0.46659209503559396, Train Accuracy: 0.9954853273137697, Val Loss 4.936776400281815, Val Accuracy: 0.9629629629629629\n",
      "Minibatch time:  9.816918134689331\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 79] Train Loss: 1.1205632431665435, Train Accuracy: 0.9865168539325843, Val Loss 5.5794525285600685, Val Accuracy: 0.9556650246305419\n",
      "Minibatch time:  9.851566553115845\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 80] Train Loss: 1.5877284412272274, Train Accuracy: 0.9820224719101124, Val Loss 5.123691746703116, Val Accuracy: 0.9533169533169533\n",
      "Minibatch time:  10.810902833938599\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 81] Train Loss: 1.2951347065682057, Train Accuracy: 0.9887387387387387, Val Loss 5.19935502341832, Val Accuracy: 0.958128078817734\n",
      "Minibatch time:  9.469132423400879\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 82] Train Loss: 0.6707767827319913, Train Accuracy: 0.9910112359550561, Val Loss 2.7687389237398747, Val Accuracy: 0.9777227722772277\n",
      "Minibatch time:  11.15808629989624\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 83] Train Loss: 1.1250968430249486, Train Accuracy: 0.9864559819413092, Val Loss 6.255319837364368, Val Accuracy: 0.9484029484029484\n",
      "Minibatch time:  9.234280824661255\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 84] Train Loss: 0.9697892203839729, Train Accuracy: 0.990990990990991, Val Loss 3.8452793258038582, Val Accuracy: 0.9680589680589681\n",
      "Minibatch time:  8.86950421333313\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 85] Train Loss: 0.8827617780698347, Train Accuracy: 0.9909502262443439, Val Loss 5.113231603987515, Val Accuracy: 0.9754299754299754\n",
      "Minibatch time:  9.149332046508789\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 86] Train Loss: 1.087361000769306, Train Accuracy: 0.9886363636363636, Val Loss 3.2855420339183183, Val Accuracy: 0.9754299754299754\n",
      "Minibatch time:  9.153328895568848\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 87] Train Loss: 1.5783594625536352, Train Accuracy: 0.9864864864864865, Val Loss 5.110131984227337, Val Accuracy: 0.9704433497536946\n",
      "Minibatch time:  9.646024942398071\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 88] Train Loss: 2.4410166856832802, Train Accuracy: 0.9775784753363229, Val Loss 3.171944929403253, Val Accuracy: 0.9754299754299754\n",
      "Minibatch time:  10.449527263641357\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 89] Train Loss: 1.774566272040829, Train Accuracy: 0.9842696629213483, Val Loss 3.261015208438039, Val Accuracy: 0.9778325123152709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minibatch time:  10.604427576065063\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 90] Train Loss: 0.6139372915495187, Train Accuracy: 0.9955156950672646, Val Loss 3.600729194295127, Val Accuracy: 0.9681372549019608\n",
      "Minibatch time:  13.66453504562378\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 91] Train Loss: 2.470556989486795, Train Accuracy: 0.9797752808988764, Val Loss 5.23395312752109, Val Accuracy: 0.9631449631449631\n",
      "Minibatch time:  10.690376281738281\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 92] Train Loss: 1.0708199490327388, Train Accuracy: 0.9887892376681614, Val Loss 6.6028257043799385, Val Accuracy: 0.9530864197530864\n",
      "Minibatch time:  9.607048034667969\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 93] Train Loss: 0.8197484358679503, Train Accuracy: 0.9932432432432432, Val Loss 5.583934702910483, Val Accuracy: 0.9606879606879607\n",
      "Minibatch time:  9.586060523986816\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 94] Train Loss: 1.1909009336668532, Train Accuracy: 0.9864864864864865, Val Loss 6.940399537939811, Val Accuracy: 0.9484029484029484\n",
      "Minibatch time:  9.12434697151184\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 95] Train Loss: 2.0026287958025932, Train Accuracy: 0.9820224719101124, Val Loss 5.371956356277224, Val Accuracy: 0.9434889434889435\n",
      "Minibatch time:  10.107738733291626\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 96] Train Loss: 1.3709782777586952, Train Accuracy: 0.9887133182844243, Val Loss 2.6324702652636915, Val Accuracy: 0.9754299754299754\n",
      "Minibatch time:  9.704986810684204\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 97] Train Loss: 0.9279390043229796, Train Accuracy: 0.9909502262443439, Val Loss 3.4994421717710793, Val Accuracy: 0.958128078817734\n",
      "Minibatch time:  9.623038291931152\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 98] Train Loss: 0.8241047131596133, Train Accuracy: 0.9887640449438202, Val Loss 4.681870198983233, Val Accuracy: 0.9606879606879607\n",
      "Minibatch time:  11.051153898239136\n",
      "----------------------------------------------------------------------------------------------------\n",
      "[Epoch 99] Train Loss: 1.2161933491879608, Train Accuracy: 0.9820224719101124, Val Loss 5.345144076272845, Val Accuracy: 0.9582309582309583\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tAccurs=[]\n",
    "tLosses=[]\n",
    "vAccurs=[]\n",
    "vLosses=[]\n",
    "gnn_model = GnnNew().to(device)\n",
    "gnn_optimizer = torch.optim.Adam(gnn_model.parameters(), lr=0.001)\n",
    "gnn_best_model = 'RP_best_model.model'\n",
    "gnn_last_model = 'RP_last_model.model'\n",
    "\n",
    "\n",
    "for num_epoch in range(epochs):\n",
    "        \n",
    "    train_loss=0\n",
    "    y_pred=[]\n",
    "    y_true=[]\n",
    "    \n",
    "    t_start = time.time()\n",
    "    gnn_model.train()        \n",
    "    \n",
    "    edges, non_edges = sample_equal_number_edges_non_edges(adj_train_corrupted, false_non_edges=train_false_non_edges, false_edges=train_false_edges, small_samples=small_samples)\n",
    "    \n",
    "    samples = torch.cat((torch.Tensor(edges), torch.Tensor(non_edges)),dim=0).type(torch.long).to(device)\n",
    "    target = torch.cat((torch.ones(len(edges)), torch.zeros(len(non_edges))),dim=0).type(torch.long).to(device)\n",
    "       \n",
    "    if minibatch_size > 0:\n",
    "        train_batcher = MiniBatcher(minibatch_size, len(samples))\n",
    "    else:\n",
    "        train_batcher = MiniBatcher(len(samples), len(samples))\n",
    "\n",
    "    for idxs in train_batcher.get_one_batch():\n",
    "        idxs = idxs.to(device)        \n",
    "        train_edges=samples[idxs]\n",
    "        train_target=target[idxs]        \n",
    "        nodex=torch.flatten(train_edges)  \n",
    "        train_nodes=torch.unique(nodex.view(-1))\n",
    "        \n",
    "        #NewSubgraphMaker(Graph, edges, nodes)\n",
    "        \n",
    "        \n",
    "        #subgraphs=NewSubgraphMaker(G_train, train_edges, nodex) \n",
    "        Graph=G_train        \n",
    "        neighbor=NeighborSamplerNew(Graph)             \n",
    "        graphGenerator=neighbor(nodex.cpu())    \n",
    "        subgraphs=[]\n",
    "        for graph in graphGenerator:  \n",
    "            #print(\"subgraphNnode \",graph.num_nodes)\n",
    "           # print(\"subgraphNid \",graph.n_id)\n",
    "            #print(\"subgraphBid \",graph.b_id)\n",
    "            sub_feature=torch.Tensor(Graph.x[graph.n_id])      \n",
    "            x_feature=[]        \n",
    "            for i in range(2):\n",
    "                unique_feature=torch.zeros(len(sub_feature),1)\n",
    "                for i_d in range(len(graph.n_id)):\n",
    "                        if graph.b_id[i]==graph.n_id[i_d]:\n",
    "                            pointu=i_d\n",
    "                            break;           \n",
    "                unique_feature[pointu]=1                        \n",
    "                x_feature.append(torch.cat((sub_feature,unique_feature),dim=1).to(device))\n",
    "            graph.x_feature=x_feature\n",
    "            subgraphs.append(graph.to(device))   \n",
    "        \n",
    "        gnn_optimizer.zero_grad()                \n",
    "        loss, pred=gnn_model.predict(subgraphs, train_nodes, train_edges, train_target)\n",
    "        \n",
    "        loss.backward()\n",
    "        gnn_optimizer.step()\n",
    "        \n",
    "        train_loss+=loss.item()\n",
    "            \n",
    "        pred = F.log_softmax(pred, dim=1)\n",
    "        pred = pred.detach().to(\"cpu\").numpy()\n",
    "        pred = np.argmax(pred, axis=1)\n",
    "\n",
    "        y_pred = np.append(y_pred,pred)\n",
    "        y_true = np.append(y_true,train_target.detach().to(\"cpu\").numpy())\n",
    "        \n",
    "    \n",
    "    t_end= time.time()\n",
    "    print(\"Minibatch time: \",t_end-t_start)\n",
    "    \n",
    "    train_acc=accuracy_score(y_true, y_pred)\n",
    "    tAccurs.append(train_acc)\n",
    "    tLosses.append(train_loss)\n",
    "    #predict_model(select, G_data, minibatch_size, small_samples):\n",
    "    v_loss,v_acc,_,_=predict_model(\"val\")\n",
    "    vLosses.append(v_loss)\n",
    "    vAccurs.append(v_acc)\n",
    "    \n",
    "    if v_acc > validation_acc:\n",
    "            validation_acc = v_acc\n",
    "            torch.save(gnn_model.state_dict(), gnn_best_model)\n",
    "    \n",
    "    print(\"-\"*100)\n",
    "    print(\"[Epoch {0}] Train Loss: {1}, Train Accuracy: {2}, Val Loss {3}, Val Accuracy: {4}\".format(num_epoch, train_loss, train_acc, v_loss, v_acc))\n",
    "    \n",
    "torch.save(gnn_model.state_dict(), gnn_last_model)\n",
    "\n",
    "save_plot(tAccurs, vAccurs, name='Accuracy')\n",
    "save_plot(tLosses, vLosses, name='Loss')        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass on the test graphs (best model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9412916099515466 (0.0029986183164883874)\n",
      "Test Micro F1 Score:  0.9412916099515466\n",
      "Test Weighted F1 Score:  0.9412889994019298\n",
      "Test Accuracy Score:  0.9412916099515466\n"
     ]
    }
   ],
   "source": [
    "#gnn_best_model = 'RP_best_model.model'\n",
    "#gnn_model = GnnNew().to(device)\n",
    "gnn_model.load_state_dict(torch.load('RP_best_model.model'))\n",
    "\n",
    "from statistics import mean, stdev\n",
    "run_count=12\n",
    "\n",
    "test_accs=[]\n",
    "test_micros=[]\n",
    "test_weighteds=[]\n",
    "\n",
    "for i in range(run_count):\n",
    "    #predict_model(select, G_data, minibatch_size, small_samples):\n",
    "    _,test_acc,test_micro,test_weighted=predict_model(\"test\")\n",
    "    test_accs.append(test_acc)\n",
    "    test_micros.append(test_micro)\n",
    "    test_weighteds.append(test_weighted)\n",
    "    \n",
    "print(\"{0} ({1})\".format(mean(test_micros), stdev(test_micros)))\n",
    "\n",
    "print(\"Test Micro F1 Score: \", mean(test_micros))\n",
    "print(\"Test Weighted F1 Score: \", mean(test_weighteds))\n",
    "print(\"Test Accuracy Score: \", mean(test_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass on the test graphs (last model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9428090658387438 (0.002807733515002018)\n",
      "Test Micro F1 Score:  0.9428090658387438\n",
      "Test Weighted F1 Score:  0.9428075284818581\n",
      "Test Accuracy Score:  0.9428090658387438\n"
     ]
    }
   ],
   "source": [
    "#gnn_last_model = 'RP_last_model.model'\n",
    "gnn_model = GnnNew().to(device)\n",
    "gnn_model.load_state_dict(torch.load('RP_last_model.model'))\n",
    "\n",
    "from statistics import mean, stdev\n",
    "run_count=12\n",
    "\n",
    "test_accs=[]\n",
    "test_micros=[]\n",
    "test_weighteds=[]\n",
    "\n",
    "for i in range(run_count):\n",
    "    _,test_acc,test_micro,test_weighted=predict_model(\"test\")\n",
    "    test_accs.append(test_acc)\n",
    "    test_micros.append(test_micro)\n",
    "    test_weighteds.append(test_weighted)\n",
    "    \n",
    "print(\"{0} ({1})\".format(mean(test_micros), stdev(test_micros)))\n",
    "    \n",
    "print(\"Test Micro F1 Score: \", mean(test_micros))\n",
    "print(\"Test Weighted F1 Score: \", mean(test_weighteds))\n",
    "print(\"Test Accuracy Score: \", mean(test_accs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([8, 4])\n",
      "tensor([2, 0])\n",
      "tensor([5, 7])\n",
      "tensor([3, 6])\n",
      "tensor([9, 1])\n",
      "\n",
      "tensor([5, 9])\n",
      "tensor([6, 3])\n",
      "tensor([0, 4])\n",
      "tensor([8, 7])\n",
      "tensor([2, 1])\n",
      "\n",
      "tensor([9, 7])\n",
      "tensor([0, 1])\n",
      "tensor([2, 5])\n",
      "tensor([6, 3])\n",
      "tensor([4, 8])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_batcher = MiniBatcher(2, 10) if minibatch_size > 0 else MiniBatcher(10, 10)\n",
    "\n",
    "for i in range(3):\n",
    "    for train_idxs in train_batcher.get_one_batch():\n",
    "        print(train_idxs)\n",
    "    print(\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2] [2 2 0]\n",
      "tensor([[3., 2.],\n",
      "        [3., 3.],\n",
      "        [4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "a=torch.Tensor([[1,2],[3,1],[4,5]])\n",
    "b=torch.unique(torch.flatten(a).view(-1))\n",
    "\n",
    "k=1\n",
    "A = kneighbors_graph(a, k, mode=\"connectivity\", metric=\"cosine\", include_self=False)        \n",
    "(u,v)=A.nonzero()\n",
    "print(u,v)\n",
    "\n",
    "a[a==1]=3\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-fb0ecfd61f25>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(np.random.randint(2))\n",
    "    \n",
    "    print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_37",
   "language": "python",
   "name": "deep_37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
